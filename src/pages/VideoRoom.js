import React, { useState, useEffect, useRef } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import { HandLandmarker, FilesetResolver, DrawingUtils } from "@mediapipe/tasks-vision";
import * as tf from '@tensorflow/tfjs';
import './../styles/VideoRoom.css';

// ParticipantViewëŠ” ì›ê²© ì°¸ê°€ììš©ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
const ParticipantView = ({ name }) => {
  return (
    <div className="participant-view">
      <video autoPlay playsInline className="video-feed"></video>
      <div className="participant-name">{name}</div>
    </div>
  );
};

function VideoRoom() {
  const { meetingCode } = useParams();
  const navigate = useNavigate();
  const [roomInfo, setRoomInfo] = useState({ name: 'í…ŒìŠ¤íŠ¸ ì±„íŒ…ë°©' });
  const [participants, setParticipants] = useState([
    { id: 'remote1', name: 'ì°¸ê°€ì 1' },
  ]);

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const [handLandmarker, setHandLandmarker] = useState(null);
  const [gestureModel, setGestureModel] = useState(null);
  const [actions, setActions] = useState([]); // í•™ìŠµëœ ì œìŠ¤ì²˜ ì´ë¦„ ëª©ë¡
  const [isCameraOn, setIsCameraOn] = useState(true);
  const [isMicOn, setIsMicOn] = useState(true);
  const [volume, setVolume] = useState(1.0);
  const [cursorPosition, setCursorPosition] = useState({ x: 0, y: 0 });
  const [isCursorVisible, setIsCursorVisible] = useState(false);
  const [isGrabbing, setIsGrabbing] = useState(false);
  const [stickerPosition, setStickerPosition] = useState({ x: 50, y: 50 });
  const [stickerSize, setStickerSize] = useState(50);
  const [isDrawingMode, setIsDrawingMode] = useState(false);
  const [isPainting, setIsPainting] = useState(false);
  const [isVideoReady, setIsVideoReady] = useState(false); // ì¹´ë©”ë¼ ì¤€ë¹„ ìƒíƒœ ì¶”ê°€
  const [lines, setLines] = useState([]);
  const [color, setColor] = useState('#000000');
  const [lineWidth, setLineWidth] = useState(5);
  const [detectionResults, setDetectionResults] = useState(null);
  const [showLandmarks, setShowLandmarks] = useState(true);
  const [currentGestureText, setCurrentGestureText] = useState('ì œìŠ¤ì²˜ ì—†ìŒ');
  const lastGesture = useRef(null);
  const gestureTimeout = useRef(null);
  const exitTimeout = useRef(null);

  const toggleCamera = (status) => {
    if (videoRef.current && videoRef.current.srcObject) {
      const tracks = videoRef.current.srcObject.getVideoTracks();
      if (tracks.length > 0) {
        tracks[0].enabled = status;
        setIsCameraOn(status);
      }
    }
  };

  const toggleMic = () => {
    setIsMicOn(prev => !prev);
  };

  const changeVolume = (amount) => {
    setVolume(prev => Math.max(0, Math.min(1, prev + amount)));
  };

  const handleLeaveRoom = () => {
    navigate('/main');
  };

  // ì œìŠ¤ì²˜ ê¸°ë°˜ ê·¸ë¦¬ê¸° ë¡œì§ (ëª¨ë¸ ì˜ˆì¸¡ ì‚¬ìš©)
  useEffect(() => {
    if (!isDrawingMode || !detectionResults || !detectionResults.landmarks || detectionResults.landmarks.length === 0) return;

    const currentGesture = currentGestureText;
    const landmarks = detectionResults.landmarks[0];
    const cursorX = landmarks[8].x * canvasRef.current.width;
    const cursorY = landmarks[8].y * canvasRef.current.height;

    if (currentGesture === 'grab') {
      if (!isPainting) {
        setLines(prevLines => [...prevLines, { points: [{ x: cursorX, y: cursorY }], color, lineWidth }]);
        setIsPainting(true);
      } else {
        setLines(prevLines => {
          const lastLine = prevLines[prevLines.length - 1];
          const newPoints = [...lastLine.points, { x: cursorX, y: cursorY }];
          const newLine = { ...lastLine, points: newPoints };
          return [...prevLines.slice(0, -1), newLine];
        });
      }
    } else {
      if (isPainting) {
        setIsPainting(false);
      }
    }
  }, [detectionResults, isDrawingMode, currentGestureText, color, lineWidth, isPainting]);

  const clearCanvas = () => {
    setLines([]);
  };

  // ì œìŠ¤ì²˜ì— ë”°ë¥¸ ì•¡ì…˜ ì²˜ë¦¬ (ì»¤ì„œ, ë³¼ë¥¨ ë“±)
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    if (!detectionResults || !detectionResults.landmarks || detectionResults.landmarks.length === 0) {
      setIsCursorVisible(false);
      return;
    }

    const landmarks = detectionResults.landmarks[0];
    
    // ì œìŠ¤ì²˜ë³„ ì•¡ì…˜ ë¶„ê¸°
    switch (currentGestureText) {
      case 'cursor':
        const cursorX = (1 - landmarks[8].x) * canvas.clientWidth;
        const cursorY = landmarks[8].y * canvas.clientHeight;
        setCursorPosition({ x: cursorX, y: cursorY });
        setIsCursorVisible(true);
        break;
      
      // TODO: ì•„ë˜ ì œìŠ¤ì²˜ë“¤ì— ëŒ€í•œ ì‹¤ì œ ì•¡ì…˜ í•¨ìˆ˜ë¥¼ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤.
      case 'volume_up':
        // ì˜ˆ: changeVolume(0.1);
        console.log("Volume Up");
        setIsCursorVisible(false);
        break;
      
      case 'volume_down':
        // ì˜ˆ: changeVolume(-0.1);
        console.log("Volume Down");
        setIsCursorVisible(false);
        break;
        
      case 'mute':
        // ì˜ˆ: toggleMic();
        console.log("Mute");
        setIsCursorVisible(false);
        break;

      default:
        // ê·¸ ì™¸ ëª¨ë“  ì œìŠ¤ì²˜ëŠ” ì»¤ì„œë¥¼ ìˆ¨ê¹ë‹ˆë‹¤.
        setIsCursorVisible(false);
        break;
    }
    
  }, [currentGestureText, detectionResults]);

  // MediaPipe ë° ì œìŠ¤ì²˜ ëª¨ë¸ ì´ˆê¸°í™”
  useEffect(() => {
    const loadModels = async () => {
      try {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
        const newHandLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 2
        });
        setHandLandmarker(newHandLandmarker);
        console.log("Hand Landmarker ë¡œë“œ ì™„ë£Œ.");

        console.log("TensorFlow.js ëª¨ë¸ ë¡œë”© ì‹œì‘...");
        const model = await tf.loadGraphModel('/tfjs_model/model.json'); // loadLayersModel -> loadGraphModelë¡œ ë³€ê²½
        setGestureModel(model);
        console.log("TensorFlow.js ëª¨ë¸ ë¡œë”© ì„±ê³µ.");
        
        // Python í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì˜ ì •ë ¬ëœ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
        const actionList = ['camera_toggle', 'cursor', 'draw_mode', 'exit_room', 'grab', 'mute', 'resize', 'volume_down', 'volume_up'];
        setActions(actionList);
        console.log("í•™ìŠµëœ ì œìŠ¤ì²˜ ëª©ë¡:", actionList);

      } catch (error) {
        console.error("AI ëª¨ë¸ ë¡œë”© ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ:", error);
      }
    };
    loadModels();
  }, []);

  // 1. ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì¦‰ì‹œ ì„¤ì •
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    const enableWebcam = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.addEventListener('loadeddata', () => {
          setIsVideoReady(true);
          console.log("ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ.");
        });
      } catch (err) {
        console.error("Error accessing webcam: ", err);
      }
    };

    enableWebcam();

    return () => {
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // 2. ëª¨ë¸ ë¡œë“œ ë° ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ í›„ ì œìŠ¤ì²˜ ê°ì§€ ë£¨í”„ ì‹œì‘
  useEffect(() => {
    if (!handLandmarker || !gestureModel || !isVideoReady) return;

    const video = videoRef.current;
    let animationFrameId;

    const predictWebcam = () => {
      if (video.readyState >= 2) {
        const results = handLandmarker.detectForVideo(video, Date.now());
        setDetectionResults(results);
        
        if (results.landmarks && results.landmarks.length > 0 && actions.length > 0) {
          try {
            const landmarks = results.landmarks[0].flatMap(lm => [lm.x, lm.y, lm.z]);
            const inputTensor = tf.tensor2d([landmarks]);
            
            const prediction = gestureModel.predict(inputTensor);
            const predictedIndex = prediction.argMax(1).dataSync()[0];
            const predictedGesture = actions[predictedIndex];
            
            // console.log("ì˜ˆì¸¡ëœ ì œìŠ¤ì²˜:", predictedGesture); // ë¡œê·¸ ì¶”ê°€
            setCurrentGestureText(predictedGesture);
            tf.dispose([inputTensor, prediction]);
          } catch (error) {
            console.error("ì œìŠ¤ì²˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜:", error);
          }
        } else {
          setCurrentGestureText('ì œìŠ¤ì²˜ ì—†ìŒ');
        }
      }
      animationFrameId = requestAnimationFrame(predictWebcam);
    };

    console.log("ì œìŠ¤ì²˜ ì˜ˆì¸¡ ì‹œì‘.");
    predictWebcam();

    return () => {
      cancelAnimationFrame(animationFrameId);
    };
  }, [handLandmarker, gestureModel, isVideoReady, actions]);

  // ìº”ë²„ìŠ¤ ë Œë”ë§
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    const context = canvas.getContext('2d');
    
    const parent = canvas.parentElement;
    if (parent) {
      canvas.width = parent.clientWidth;
      canvas.height = parent.clientHeight;
    }

    context.clearRect(0, 0, canvas.width, canvas.height);

    lines.forEach(line => {
      context.strokeStyle = line.color;
      context.lineWidth = line.lineWidth;
      context.lineCap = 'round';
      context.lineJoin = 'round';
      context.beginPath();
      line.points.forEach((point, index) => {
        if (index === 0) context.moveTo(point.x, point.y);
        else context.lineTo(point.x, point.y);
      });
      context.stroke();
    });

    if (showLandmarks && detectionResults && detectionResults.landmarks) {
      const drawingUtils = new DrawingUtils(context);
      for (const landmarks of detectionResults.landmarks) {
        drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 5 });
        drawingUtils.drawLandmarks(landmarks, { color: "#FF0000", lineWidth: 2 });
      }
    }
  }, [lines, detectionResults, showLandmarks]);

  return (
    <div className="video-room-container">
      <header className="room-header">
        <h2>{roomInfo ? roomInfo.name : 'ë¡œë”© ì¤‘...'}</h2>
      </header>
      <div className="main-content-wrapper">
        <div className="video-grid-main">
          <div className="participant-view local">
            <video ref={videoRef} autoPlay playsInline muted className="video-feed"></video>
            <canvas ref={canvasRef} className="output_canvas"></canvas>
            <div className="gesture-display">{currentGestureText}</div>
            {isCursorVisible && <div className="cursor" style={{ left: `${cursorPosition.x}px`, top: `${cursorPosition.y}px` }}></div>}
            <div 
              className="sticker" 
              style={{ 
                left: `${stickerPosition.x}px`, 
                top: `${stickerPosition.y}px`,
                width: `${stickerSize}px`,
                height: `${stickerSize}px`,
                fontSize: `${stickerSize * 0.8}px`
              }}
            >ğŸ¨</div>
            <div className="participant-name">ë‚˜</div>
          </div>
          {participants.map(p => (
            <ParticipantView key={p.id} name={p.name} />
          ))}
        </div>
        <div className="chat-panel">
        </div>
      </div>
      <div className="controls-bar">
        {/* Left-aligned controls (empty for now) */}
        <div className="control-group"></div>

        {/* Center-aligned controls */}
        <div className="control-group control-buttons">
          <button onClick={() => toggleCamera(!isCameraOn)} title={isCameraOn ? 'ì¹´ë©”ë¼ ë„ê¸°' : 'ì¹´ë©”ë¼ ì¼œê¸°'}>
            {isCameraOn ? 'ğŸ“·' : 'ğŸ“¸'}
          </button>
          <button onClick={toggleMic} title={isMicOn ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}>
            {isMicOn ? 'ğŸ¤' : 'ğŸ”‡'}
          </button>
          <button onClick={() => setIsDrawingMode(prev => !prev)} title={isDrawingMode ? 'ê·¸ë¦¬ê¸° ì¢…ë£Œ' : 'ê·¸ë¦¬ê¸° ì‹œì‘'}>
            âœï¸
          </button>
          <button onClick={() => setShowLandmarks(prev => !prev)} title={showLandmarks ? 'ê´€ì ˆ ìˆ¨ê¸°ê¸°' : 'ê´€ì ˆ ë³´ì´ê¸°'}>
            ğŸ–ï¸
          </button>
        </div>

        {/* Right-aligned controls */}
        <div className="control-group">
          <button className="leave-btn" onClick={handleLeaveRoom} title="ë‚˜ê°€ê¸°">ğŸšª ë‚˜ê°€ê¸°</button>
        </div>

        {/* Drawing tools palette */}
        {isDrawingMode && (
          <div className="drawing-controls">
            <input type="color" value={color} onChange={(e) => setColor(e.target.value)} title="ìƒ‰ìƒ ì„ íƒ" />
            <input type="range" min="1" max="20" value={lineWidth} onChange={(e) => setLineWidth(e.target.value)} title="ì„  êµµê¸°" />
            <button onClick={clearCanvas} title="ì „ì²´ ì§€ìš°ê¸°">ğŸ—‘ï¸</button>
          </div>
        )}
      </div>
    </div>
  );
}

export default VideoRoom;
